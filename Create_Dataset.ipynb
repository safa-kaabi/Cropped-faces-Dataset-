{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c080d607",
   "metadata": {},
   "source": [
    "# 1. Generating dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32721e0c",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected image 1\n",
      "Collected image 2\n",
      "Collected image 3\n",
      "Collected image 4\n",
      "Collected image 5\n",
      "Collected image 6\n",
      "Collected image 7\n",
      "Collected image 8\n",
      "Collected image 9\n",
      "Collected image 10\n",
      "Collected image 11\n",
      "Collected image 12\n",
      "Collected image 13\n",
      "Collected image 14\n",
      "Collected image 15\n",
      "Collected image 16\n",
      "Collected image 17\n",
      "Collected image 18\n",
      "Collected image 19\n",
      "Collected image 20\n",
      "Collected image 21\n",
      "Collected image 22\n",
      "Collected image 23\n",
      "Collected image 24\n",
      "Collected image 25\n",
      "Collected image 26\n",
      "Collected image 27\n",
      "Collected image 28\n",
      "Collected image 29\n",
      "Collected image 30\n",
      "Collected image 31\n",
      "Collected image 32\n",
      "Collected image 33\n",
      "Collected image 34\n",
      "Collected image 35\n",
      "Collected image 36\n",
      "Collected image 37\n",
      "Collected image 38\n",
      "Collected image 39\n",
      "Collected image 40\n",
      "Collected image 41\n",
      "Collected image 42\n",
      "Collected image 43\n",
      "Collected image 44\n",
      "Collected image 45\n",
      "Collected image 46\n",
      "Collected image 47\n",
      "Collected image 48\n",
      "Collected image 49\n",
      "Collected image 50\n",
      "Collected image 51\n",
      "Collected image 52\n",
      "Collected image 53\n",
      "Collected image 54\n",
      "Collected image 55\n",
      "Collected image 56\n",
      "Collected image 57\n",
      "Collected image 58\n",
      "Collected image 59\n",
      "Collected image 60\n",
      "Collected image 61\n",
      "Collected image 62\n",
      "Collected image 63\n",
      "Collected image 64\n",
      "Collected image 65\n",
      "Collected image 66\n",
      "Collected image 67\n",
      "Collected image 68\n",
      "Collected image 69\n",
      "Collected image 70\n",
      "Collected image 71\n",
      "Collected image 72\n",
      "Collected image 73\n",
      "Collected image 74\n",
      "Collected image 75\n",
      "Collected image 76\n",
      "Collected image 77\n",
      "Collected image 78\n",
      "Collected image 79\n",
      "Collected image 80\n",
      "Collected image 81\n",
      "Collected image 82\n",
      "Collected image 83\n",
      "Collected image 84\n",
      "Collected image 85\n",
      "Collected image 86\n",
      "Collected image 87\n",
      "Collected image 88\n",
      "Collected image 89\n",
      "Collected image 90\n",
      "Collected image 91\n",
      "Collected image 92\n",
      "Collected image 93\n",
      "Collected image 94\n",
      "Collected image 95\n",
      "Collected image 96\n",
      "Collected image 97\n",
      "Collected image 98\n",
      "Collected image 99\n",
      "Collected image 100\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Load the Haar Cascade classifier for face detection\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Set the directory to save the collected images\n",
    "save_directory = 'collected_images'\n",
    "\n",
    "# Create the directory if it does not exist\n",
    "if not os.path.exists(save_directory):\n",
    "    os.makedirs(save_directory)\n",
    "\n",
    "# Initialize the video capture object\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Initialize the number of images collected\n",
    "num_images = 0\n",
    "\n",
    "# Loop through the frames as they become available\n",
    "while num_images < 100:\n",
    "    # Capture a frame from the camera\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Convert the frame to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect faces in the grayscale frame\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=5)\n",
    "\n",
    "    # Draw rectangles around the detected faces\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "        # Create a file name for the image based on the current count\n",
    "        file_name = f'{save_directory}/safa_image_{num_images}.jpg'\n",
    "\n",
    "        # Crop the face from the frame and save it as a new image file\n",
    "        face_image = frame[y:y+h, x:x+w]\n",
    "        cv2.imwrite(file_name, face_image)\n",
    "        time.sleep(0.5)\n",
    "\n",
    "        # Increment the number of images collected\n",
    "        num_images += 1\n",
    "\n",
    "        # Print a message for each image collected\n",
    "        print(f'Collected image {num_images}')\n",
    "\n",
    "        # Exit if the desired number of images has been collected\n",
    "        if num_images >= 100:\n",
    "            break\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Collecting Images', frame)\n",
    "\n",
    "    # Exit if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture object and destroy all OpenCV windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9a8308",
   "metadata": {},
   "source": [
    "#  2. Create data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "585f514a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from random import shuffle\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6bd711e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_data():\n",
    "    data = []\n",
    "    for img in tqdm (os.listdir(\"collected_images\")):\n",
    "            path = os.path.join(save_directory, img)\n",
    "            img_data = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "            img_data = cv2.resize(img_data, (50, 50))\n",
    "            data.append([np.array(img_data)])\n",
    "    shuffle(data)  \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "682484e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:00<00:00, 62.77it/s]\n"
     ]
    }
   ],
   "source": [
    "data = my_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2290bc7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
